{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3af18e8b-df77-4a89-815e-8ba10134994c",
   "metadata": {},
   "source": [
    "# imports and utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b5158f-2833-4ad8-96ed-7a73bbbff66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model loader - imagenet\n",
    "\n",
    "import sys\n",
    "sys.path.append(\".\")\n",
    "sys.path.append(\"./latent-diffusion\")\n",
    "sys.path.append('./taming-transformers')\n",
    "\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from ldm.util import instantiate_from_config\n",
    "\n",
    "\n",
    "def load_model_from_config(config, ckpt):\n",
    "    print(f\"Loading model from {ckpt}\")\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # device = torch.device('cpu')\n",
    "    pl_sd = torch.load(ckpt, weights_only=False, map_location=torch.device('cpu'))\n",
    "    sd = pl_sd[\"state_dict\"]\n",
    "    # torch.save(sd, './tmp_sd')\n",
    "    model = instantiate_from_config(config.model)\n",
    "    m, u = model.load_state_dict(sd, strict=False)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "    model.eval()\n",
    "    return model, sd, pl_sd\n",
    "\n",
    "\n",
    "def get_model(model_config_path, model_ckpt_path):\n",
    "    config = OmegaConf.load(model_config_path)\n",
    "    model, sd, pl_sd = load_model_from_config(config, model_ckpt_path)\n",
    "    return model, sd, pl_sd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7404044-a38d-44a3-8994-0b856391bc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model loader - BraTS\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "sys.path.append(\".\")\n",
    "sys.path.append(\"./brats-mri\")\n",
    "import monai\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from monai.utils import first\n",
    "from generative.inferers import LatentDiffusionInferer\n",
    "from generative.networks.schedulers import DDIMScheduler\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from pretrained import load_autoencoder, load_unet\n",
    "import utils\n",
    "\n",
    "BUNDLE = './brats-mri/brats_mri_class_cond/'\n",
    "sys.path.append(BUNDLE)\n",
    "from scripts.inferer import LatentDiffusionInfererWithClassConditioning\n",
    "\n",
    "def get_monai_autoencoder(bundle_target, training_args, weights_override_path):\n",
    "    # load autoencoder\n",
    "    autoencoder = load_autoencoder(bundle_target,\n",
    "                                   override_model_cfg_json=training_args.config,\n",
    "                                   override_weights_load_path=weights_override_path)    \n",
    "    return autoencoder\n",
    "\n",
    "def get_monai_unet(bundle_target, training_args, weights_override_path):\n",
    "    unet = load_unet(bundle_target,\n",
    "                     context_conditioning=training_args.conditioning == 'context',\n",
    "                     override_model_cfg_json=training_args.config,\n",
    "                     override_weights_load_path=weights_override_path,\n",
    "                     use_conditioning=True)\n",
    "    return unet\n",
    "    \n",
    "def get_monai_model_dict(bundle_target, training_args, autoencoder_weights_path, unet_weights_path):\n",
    "    monai_dict = {}\n",
    "    training_args = torch.load(os.path.join(output_dir, training_name, 'training_args'))\n",
    "    monai_dict['autoencoder'] = get_monai_autoencoder(bundle_target, training_args, autoencoder_weights_path)\n",
    "    monai_dict['unet'] = get_monai_unet(bundle_target, training_args, unet_weights_path)\n",
    "    \n",
    "    # set scheduler\n",
    "    config = utils.model_config(bundle_target, training_args.config)\n",
    "    monai_dict['scheduler'] = config.get_parsed_content('noise_scheduler')\n",
    "    # set inferer\n",
    "    if training_args.conditioning in ['context', 'none']:\n",
    "        monai_dict['inferer'] = LatentDiffusionInferer(scheduler=scheduler, scale_factor=scale_factor)\n",
    "    else:\n",
    "        monai_dict['inferer'] = LatentDiffusionInfererWithClassConditioning(scheduler=scheduler, scale_factor=scale_factor)\n",
    "    return monai_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f86e46-e829-49f7-a2d4-5602b727d9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix plotter\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def labels_to_human_labels(labels, human_labels_list):\n",
    "    human_labels = [human_labels_list[int(x.detach().cpu().numpy())] for x in labels]  \n",
    "    return human_labels\n",
    "\n",
    "def plot_confusion_matrix(true_labels, labels_pred, human_labels_list):\n",
    "    true_labels_readable = labels_to_human_labels(true_labels, human_labels_list)\n",
    "    labels_pred_readable = labels_to_human_labels(labels_pred, human_labels_list)\n",
    "    cm = confusion_matrix(true_labels_readable, labels_pred_readable, labels=human_labels_list)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                                  display_labels=human_labels_list)\n",
    "    fig, ax = plt.subplots(figsize=(12,12))\n",
    "    disp.plot(ax=ax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb771c99-d0d3-49f5-a8cf-799f2581ae38",
   "metadata": {},
   "source": [
    "# ImageNet-mini LDM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb614885-aaa6-41b8-9f4e-cc14ddd59ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load imagenet pretrained model\n",
    "import os\n",
    "\n",
    "def get_model2(model_config_path, model_ckpt_path):\n",
    "    config = OmegaConf.load(model_config_path)\n",
    "    model, sd, pl_sd = load_model_from_config(config, model_ckpt_path)\n",
    "    return model, sd, pl_sd\n",
    "    \n",
    "def load_model_from_config2(config, ckpt):\n",
    "    print(f\"Loading model from {ckpt}\")\n",
    "    pl_sd = torch.load(ckpt, weights_only=False, map_location=torch.device('cpu'))\n",
    "    sd = pl_sd[\"state_dict\"]\n",
    "    model = instantiate_from_config(config.model)\n",
    "    m, u = model.load_state_dict(sd, strict=False)\n",
    "    model.eval()\n",
    "    return model.to(device), sd, pl_sd\n",
    "\n",
    "cin_model_config_path = os.path.join('./latent-diffusion/configs/latent-diffusion/cin256-v2.yaml')\n",
    "cin_model_ckpt_path = './latent-diffusion/models/ldm/cin256-v2/model.ckpt'\n",
    "\n",
    "# load model\n",
    "model, sd, pl_sd = get_model2(cin_model_config_path, cin_model_ckpt_path)\n",
    "del sd\n",
    "del pl_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94d0d8c-062b-4219-89cc-3948946196f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./diffusion_classifier')\n",
    "# set ldm classifier\n",
    "\n",
    "from ldm_classifier_imagenet import LdmClassifier\n",
    "ldm_clf = LdmClassifier(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a96740f-13b1-474c-98c0-81a0ca137a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./latent-diffusion/ldm/data/')\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from imagenet_mini import ImageNetMiniSubset, ImageNetMiniDataset\n",
    "\n",
    "# define imagenet-mini subset for classification\n",
    "\n",
    "val_dir = './data/imagenet-mini/validation'\n",
    "subset_classes = [3, 852, 14, 222, 888, 173, 405, 16]\n",
    "imagnet_subset = ImageNetMiniSubset(data_dir=val_dir, labels_file='validation_set.csv', size=256, classes=subset_classes)\n",
    "\n",
    "print(f\"number of samples in dataset: {len(imagnet_subset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef59704-6440-4804-a3cd-250e9d4862e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify ability to classify single sample:\n",
    "\n",
    "loader = torch.utils.data.DataLoader(imagnet_subset, batch_size=1, shuffle=False)\n",
    "batch = next(iter(loader))\n",
    "c_hypotheses = ldm_clf.get_class_hypotheses_for_batch(batch_size=batch['image'].shape[0], classes=subset_classes)\n",
    "# x0 = ldm_clf.get_latent_batch(batch)\n",
    "\n",
    "%time l2_label_pred, l1_label_pred = ldm_clf.classify_batch(batch, c_hypotheses, n_trials=1, t_sampling_stride=50)\n",
    "print(f\"true label: {batch['class_label']}\")\n",
    "print(f\"L2 classification: {l2_label_pred}\")\n",
    "print(f\"L1 classification: {l1_label_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c986fc-05be-47a1-8a50-8ceca9ab13ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run classification for the entire dataset\n",
    "\n",
    "l2_labels_pred, l1_labels_pred, true_labels = ldm_clf.classify_dataset(dataset=imagnet_subset,\n",
    "                                                                       batch_size=1,\n",
    "                                                                       n_trials=1,\n",
    "                                                                       t_sampling_stride=50,\n",
    "                                                                       classes=subset_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7218cea-4b40-486c-9eb2-79e16c6b6c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_acc = ldm_clf.get_classification_accuracy(l2_labels_pred, true_labels)\n",
    "l1_acc = ldm_clf.get_classification_accuracy(l1_labels_pred, true_labels)\n",
    "\n",
    "print(f\"L2 accuracy: {l2_acc}\")\n",
    "print(f\"L1 accuracy: {l1_acc}\")\n",
    "\n",
    "plot_confusion_matrix(true_labels, l2_labels_pred, imagnet_subset.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9668ec04-359d-4a7c-af6f-c0bb8e83df69",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# CT RSNA - LDM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34480532-6912-4b1e-94a8-0ba019e6ac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir='outputs'\n",
    "model_name = \"cp_for_weights_only_chk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81bf482-ece3-43a2-a055-c66d46ea6c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ct-rsna model\n",
    "import os\n",
    "\n",
    "ct_model_config_path = f\"./data/{output_dir}/{model_name}/configs/2024-04-27T10-00-13-project.yaml\"\n",
    "ct_model_ckpt_path = f\"./data/{output_dir}/{model_name}/checkpoints/last_weights_only.ckpt\"\n",
    "\n",
    "# load model\n",
    "ct_model, _, _ = get_model(ct_model_config_path, ct_model_ckpt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c4633d-3f0e-437d-b0ba-a5b562290e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set ldm classifier\n",
    "\n",
    "\n",
    "from ldm_classifier import LdmClassifier\n",
    "ct_ldm_clf = LdmClassifier(ct_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e997c140-b9d7-4353-b67b-ae2b439d033c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./latent-diffusion/ldm/data/')\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from ct_rsna import CTSubset, CTDataset\n",
    "\n",
    "# define imagenet-mini subset for classification\n",
    "\n",
    "val_dir = './data/ct-rsna/validation'\n",
    "ct_subset = CTSubset(data_dir=val_dir, labels_file='validation_set.csv', size=256, flip_prob=0., subset_len=256)\n",
    "subset_classes = np.unique(ct_subset.labels).tolist()\n",
    "print(f\"number of samples in dataset: {len(ct_subset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14c4839-c9ff-4c8e-9264-be4bdb9d12a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify ability to classify single sample:\n",
    "\n",
    "loader = torch.utils.data.DataLoader(ct_subset, batch_size=1, shuffle=False)\n",
    "batch = next(iter(loader))\n",
    "c_hypotheses = ct_ldm_clf.get_class_hypotheses_for_batch(batch_size=batch['image'].shape[0], classes=subset_classes)\n",
    "# x0 = ldm_clf.get_latent_batch(batch)\n",
    "\n",
    "l2_label_pred, l1_label_pred = ct_ldm_clf.classify_batch(batch, c_hypotheses, t_sampling_stride=50)\n",
    "print(f\"true label: {batch['class_label']}\")\n",
    "print(f\"L2 classification: {l2_label_pred}\")\n",
    "print(f\"L1 classification: {l1_label_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f109b8b7-3365-43bb-a23c-fc252df9be03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run classification for the entire dataset\n",
    "\n",
    "l2_labels_pred, l1_labels_pred, true_labels = ct_ldm_clf.classify_dataset(dataset=ct_subset,\n",
    "                                                                          batch_size=1,\n",
    "                                                                          n_trials=1,\n",
    "                                                                          t_sampling_stride=50,\n",
    "                                                                          classes=subset_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231edc2a-71d0-4c38-9c45-a4f4b183a823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tmp_true.npy', 'wb') as f:\n",
    "    pickle.dump(true_labels, f)\n",
    "with open('tmp_l2_pred.npy', 'wb') as f:\n",
    "    pickle.dump(l2_labels_pred, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d7cc28-ac1b-4bbb-9489-905c255bc251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tmp_true.npy', 'rb') as f:\n",
    "    true_labels = pickle.load(f)\n",
    "with open('tmp_l2_pred.npy', 'rb') as f:\n",
    "    l2_labels_pred = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c156d51a-28f8-4d65-9d41-2093a387f182",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(true_labels, l2_labels_pred, ct_subset.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bc6541-25c8-4e57-a1ed-f7d9cb1ce067",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_acc = ct_ldm_clf.get_classification_accuracy(l2_labels_pred, true_labels)\n",
    "l1_acc = ct_ldm_clf.get_classification_accuracy(l1_labels_pred, true_labels)\n",
    "\n",
    "print(f\"L2 accuracy: {l2_acc}\")\n",
    "print(f\"L1 accuracy: {l1_acc}\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(true_labels, l2_labels_pred, labels=imagnet_subset.class_names)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                               display_labels=imagnet_subset.class_names)\n",
    "\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2fdbb3-3f95-4548-b89a-23f315960d33",
   "metadata": {},
   "source": [
    "# Diffusion Classifier - accuracy evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751d8401-2fe3-4445-a3b3-f1b29282cf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "# set a fixed random seed (both numpy and torch)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5743dd-0736-4e85-a51a-3822de9fdf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from enum import Enum\n",
    "import pickle\n",
    "\n",
    "from ldm_classifier import LdmClassifier, MonaiLdmClassifier\n",
    "\n",
    "def get_training_ckpt_files(output_dir, training_name):\n",
    "  ckpt_dir = os.path.join(output_dir, training_name, 'checkpoints')\n",
    "  training_ckpt_files = [os.path.join(ckpt_dir, ckpt) for ckpt in os.listdir(ckpt_dir) if 'epoch' in ckpt]\n",
    "  return training_ckpt_files\n",
    "\n",
    "def strip_epoch_num_from_ckpt(ckpt_full_path, framework_type):\n",
    "  ckpt_name = ckpt_full_path.split('/')[-1]\n",
    "  if framework_type is FrameworkType.Imagenet:\n",
    "      epoch_num = 1 + int(ckpt_name.split(\".\")[0].split(\"=\")[-1])\n",
    "  elif framework_type is FrameworkType.Monai:\n",
    "      epoch_num = int(ckpt_name.split(\".\")[0].split(\"_\")[-1])\n",
    "  else:\n",
    "      raise ValueError(f'framework_type {framework_type} not in [t for t in FrameworkType]')\n",
    "  return epoch_num\n",
    "\n",
    "def get_training_cfg_file(output_dir, training_name):\n",
    "  cfg_dir = os.path.join(output_dir, training_name, 'configs')\n",
    "  model_cfg_files = [cfg for cfg in os.listdir(cfg_dir) if 'project' in cfg]\n",
    "  if len(model_cfg_files) == 0:\n",
    "    raise ValueError(\"configs dir empty, you may manualy pass the config file instead\")\n",
    "  if len(model_cfg_files) > 1:\n",
    "    raise ValueError(\"more than 1 config file in configs dir, you may manualy pass the config file instead\")\n",
    "  \n",
    "  return os.path.join(cfg_dir, model_cfg_files[0])\n",
    "\n",
    "\n",
    "def get_monai_training_ckpt_files(output_dir, training_name):\n",
    "  ckpt_dir = os.path.join(output_dir, training_name)\n",
    "  autoencoder_ckpt_files = [os.path.join(ckpt_dir, ckpt) for ckpt in os.listdir(ckpt_dir) if 'autoencoder' in ckpt]\n",
    "  unet_ckpt_files = [os.path.join(ckpt_dir, ckpt) for ckpt in os.listdir(ckpt_dir) if 'diffusion' in ckpt]\n",
    "  return autoencoder_ckpt_files, unet_ckpt_files\n",
    "\n",
    "class FrameworkType(Enum):\n",
    "    Imagenet = 0\n",
    "    Monai = 1\n",
    "\n",
    "def evaluate_accuracy_over_epochs(output_dir, \n",
    "                                  training_name, \n",
    "                                  dataset, \n",
    "                                  framework_type: FrameworkType,\n",
    "                                  t_sampling_stride = 50,\n",
    "                                  n_trials = 1\n",
    "                                 ):\n",
    "    # create classification results dir under the training dir\n",
    "    clf_dir = os.path.join(output_dir, training_name, 'classification')\n",
    "    if not os.path.exists(clf_dir):\n",
    "        os.makedirs(clf_dir)\n",
    "    n_pred_files = len(os.listdir(clf_dir))\n",
    "\n",
    "    clf_res_per_epoch = {'dataset': dataset}\n",
    "    \n",
    "    if framework_type is FrameworkType.Imagenet:\n",
    "        # prepare files\n",
    "        training_ckpt_files = get_training_ckpt_files(output_dir, training_name)\n",
    "        cfg_file = get_training_cfg_file(output_dir, training_name)\n",
    "\n",
    "        # loop over ckpts\n",
    "        for ckpt_file in training_ckpt_files:\n",
    "            epoch_num = strip_epoch_num_from_ckpt(ckpt_file, framework_type)\n",
    "            # load model\n",
    "            model, _, _ = get_model(cfg_file, ckpt_file)\n",
    "            # instantiate ldm classifier\n",
    "            ldm_clf = LdmClassifier(model)    \n",
    "            # run classification\n",
    "            l2_labels_pred, l1_labels_pred, true_labels = ldm_clf.classify_dataset(dataset=ds,\n",
    "                                                                                   batch_size=1,\n",
    "                                                                                   n_trials=n_trials,\n",
    "                                                                                   t_sampling_stride=t_sampling_stride)\n",
    "            # save results\n",
    "            clf_res_per_epoch[epoch_num] = {\n",
    "              'true_labels': true_labels,\n",
    "              'l1_pred_labels': l1_labels_pred,\n",
    "              'l2_pred_labels': l2_labels_pred,\n",
    "            }\n",
    "            with open(os.path.join(clf_dir, f'predictions_{n_pred_files}'), 'wb') as f:\n",
    "                pickle.dump(clf_res_per_epoch, f)\n",
    "            \n",
    "            # delete model\n",
    "            del model\n",
    "            del ldm_clf\n",
    "    \n",
    "    elif framework_type is FrameworkType.Monai:\n",
    "        bundle_target\n",
    "        # prepare files\n",
    "        autencoder_ckpt_files, unet_ckpt_files = get_monai_training_ckpt_files(output_dir, training_name)\n",
    "        # loop over ckpts\n",
    "        for autoenc_ckpt, unet_ckpt in zip(autencoder_ckpt_files, unet_ckpt_files):\n",
    "            epoch_num = strip_epoch_num_from_ckpt(autoenc_ckpt, framework_type)\n",
    "            # load model\n",
    "            model_dict = get_monai_model_dict(BUNDLE, training_args, autoenc_ckpt, unet_ckpt)\n",
    "            # instantiate ldm classifier\n",
    "            ldm_clf = MonaiLdmClassifier(**model_dict)\n",
    "            # run classification\n",
    "            l2_labels_pred, l1_labels_pred, true_labels = ldm_clf.classify_dataset(dataset=ds,\n",
    "                                                                                   batch_size=1,\n",
    "                                                                                   n_trials=n_trials,\n",
    "                                                                                   t_sampling_stride=t_sampling_stride)\n",
    "            # save results\n",
    "            clf_res_per_epoch[epoch_num] = {\n",
    "              'true_labels': true_labels,\n",
    "              'l1_pred_labels': l1_labels_pred,\n",
    "              'l2_pred_labels': l2_labels_pred,\n",
    "            }\n",
    "            with open(os.path.join(clf_dir, f'predictions_{n_pred_files}'), 'wb') as f:\n",
    "                pickle.dump(clf_res_per_epoch, f)\n",
    "            \n",
    "            # delete model\n",
    "            del model\n",
    "            del ldm_clf\n",
    "    else:\n",
    "        raise ValueError(f'framework_type {framework_type} not in [t for t in FrameworkType]')\n",
    "    return clf_res_per_epoch\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3070b5ab-f2e4-400e-8eb3-081348fd21e4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# ImageNet LDM accuracy evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130d1acb-d783-4bb6-90ec-7e1b4db03cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./latent-diffusion/ldm/data/')\n",
    "from ct_rsna import CTDataset, CTSubset\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe7dced-6c84-4066-a0fd-3d0351c4aa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "train_dir = './data/ct-rsna/train'\n",
    "val_dir = './data/ct-rsna/validation'\n",
    "\n",
    "subset_len = 1\n",
    "ds = CTSubset(data_dir=val_dir, labels_file='validation_set_dropped_nans.csv', size=256, flip_prob=0., subset_len=subset_len)\n",
    "\n",
    "# LDM classifier params\n",
    "t_sampling_stride = 50\n",
    "n_trials = 1\n",
    "\n",
    "# training dir\n",
    "output_dir = './data/outputs'\n",
    "training_name = '2024-05-10T17-04-36_imagenet-1024'\n",
    "\n",
    "# evaluate\n",
    "clf_res_per_epoch = evaluate_accuracy_over_epochs(output_dir, \n",
    "                                                  training_name, \n",
    "                                                  ds, \n",
    "                                                  FrameworkType.Imagenet,\n",
    "                                                  t_sampling_stride,\n",
    "                                                  n_trials)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b23b41-7825-4ce9-95df-87f3510aa11c",
   "metadata": {},
   "source": [
    "# MONAI - classification accuracy evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f8e26d-d003-48c8-ba6a-18f8ed1abb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./latent-diffusion/ldm/data/')\n",
    "from ct_rsna import CTDataset, CTSubset\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0967e66a-72bc-4560-b983-82e86390a344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "train_dir = './data/ct-rsna/train'\n",
    "val_dir = './data/ct-rsna/validation'\n",
    "\n",
    "subset_len = 1\n",
    "ds = CTSubset(data_dir=val_dir, labels_file='validation_set_dropped_nans.csv', size=256, flip_prob=0., subset_len=subset_len)\n",
    "\n",
    "# LDM classifier params\n",
    "t_sampling_stride = 50\n",
    "n_trials = 1\n",
    "\n",
    "# training dir\n",
    "output_dir = './data/outputs'\n",
    "training_name = '2024-05-10T17-04-36_imagenet-1024'\n",
    "\n",
    "# evaluate\n",
    "clf_res_per_epoch = evaluate_accuracy_over_epochs(output_dir, \n",
    "                                                  training_name, \n",
    "                                                  ds, \n",
    "                                                  FrameworkType.Monai,\n",
    "                                                  t_sampling_stride,\n",
    "                                                  n_trials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221117ec-4275-44ec-bb1e-c093f06003a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
