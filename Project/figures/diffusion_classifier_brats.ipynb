{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727e402e-3031-4b41-880c-7b14e804db88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model loader - BraTS\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "sys.path.append(\".\")\n",
    "sys.path.append(\"./brats-mri\")\n",
    "import monai\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from monai.utils import first\n",
    "from generative.inferers import LatentDiffusionInferer\n",
    "from generative.networks.schedulers import DDIMScheduler\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from pretrained import load_autoencoder, load_unet\n",
    "import utils\n",
    "\n",
    "BUNDLE = './brats-mri/brats_mri_class_cond/'\n",
    "sys.path.append(BUNDLE)\n",
    "from scripts.inferer import LatentDiffusionInfererWithClassConditioning\n",
    "\n",
    "def get_monai_autoencoder(bundle_target, training_args, weights_override_path):\n",
    "    # load autoencoder\n",
    "    autoencoder = load_autoencoder(bundle_target,\n",
    "                                   override_model_cfg_json=training_args.config,\n",
    "                                   override_weights_load_path=weights_override_path)    \n",
    "    return autoencoder\n",
    "\n",
    "def get_monai_unet(bundle_target, training_args, weights_override_path):\n",
    "    unet = load_unet(bundle_target,\n",
    "                     context_conditioning=training_args.conditioning == 'context',\n",
    "                     override_model_cfg_json=training_args.config,\n",
    "                     override_weights_load_path=weights_override_path,\n",
    "                     use_conditioning=True)\n",
    "    return unet\n",
    "    \n",
    "def get_monai_model_dict(bundle_target, training_args, autoencoder_weights_path, unet_weights_path):\n",
    "    monai_dict = {}\n",
    "    training_args = torch.load(os.path.join(output_dir, training_name, 'training_args'))\n",
    "    monai_dict['autoencoder'] = get_monai_autoencoder(bundle_target, training_args, autoencoder_weights_path)\n",
    "    monai_dict['unet'] = get_monai_unet(bundle_target, training_args, unet_weights_path)\n",
    "    \n",
    "    # set scheduler\n",
    "    config = utils.model_config(bundle_target, training_args.config)\n",
    "    monai_dict['scheduler'] = config.get_parsed_content('noise_scheduler')\n",
    "    # set inferer\n",
    "    if training_args.conditioning in ['context', 'none']:\n",
    "        monai_dict['inferer'] = LatentDiffusionInferer(scheduler=scheduler, scale_factor=scale_factor)\n",
    "    else:\n",
    "        monai_dict['inferer'] = LatentDiffusionInfererWithClassConditioning(scheduler=scheduler, scale_factor=scale_factor)\n",
    "    return monai_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa23527-acae-49b6-865a-cef20b7352cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix plotter\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def labels_to_human_labels(labels, human_labels_list):\n",
    "    human_labels = [human_labels_list[int(x.detach().cpu().numpy())] for x in labels]  \n",
    "    return human_labels\n",
    "\n",
    "def plot_confusion_matrix(true_labels, labels_pred, human_labels_list):\n",
    "    true_labels_readable = labels_to_human_labels(true_labels, human_labels_list)\n",
    "    labels_pred_readable = labels_to_human_labels(labels_pred, human_labels_list)\n",
    "    cm = confusion_matrix(true_labels_readable, labels_pred_readable, labels=human_labels_list)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                                  display_labels=human_labels_list)\n",
    "    fig, ax = plt.subplots(figsize=(12,12))\n",
    "    disp.plot(ax=ax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e31831-065b-4d42-80b7-f656dd9bff56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from enum import Enum\n",
    "import pickle\n",
    "\n",
    "from ldm_classifier_brats import MonaiLdmClassifier\n",
    "\n",
    "def strip_epoch_num_from_ckpt(ckpt_full_path):\n",
    "  ckpt_name = ckpt_full_path.split('/')[-1]  \n",
    "  epoch_num = int(ckpt_name.split(\".\")[0].split(\"_\")[-1])\n",
    "  return epoch_num\n",
    "\n",
    "def get_monai_training_ckpt_files(output_dir, training_name):\n",
    "  ckpt_dir = os.path.join(output_dir, training_name)\n",
    "  autoencoder_ckpt_files = [os.path.join(ckpt_dir, ckpt) for ckpt in os.listdir(ckpt_dir) if 'autoencoder' in ckpt]\n",
    "  unet_ckpt_files = [os.path.join(ckpt_dir, ckpt) for ckpt in os.listdir(ckpt_dir) if 'diffusion' in ckpt]\n",
    "  return autoencoder_ckpt_files, unet_ckpt_files\n",
    "\n",
    "def evaluate_accuracy_over_epochs(output_dir, \n",
    "                                  training_name, \n",
    "                                  dataset, \n",
    "                                  framework_type: FrameworkType,\n",
    "                                  t_sampling_stride = 50,\n",
    "                                  n_trials = 1\n",
    "                                 ):\n",
    "    # create classification results dir under the training dir\n",
    "    clf_dir = os.path.join(output_dir, training_name, 'classification')\n",
    "    if not os.path.exists(clf_dir):\n",
    "        os.makedirs(clf_dir)\n",
    "    n_pred_files = len(os.listdir(clf_dir))\n",
    "\n",
    "    clf_res_per_epoch = {'dataset': dataset}\n",
    "    # prepare files\n",
    "    autencoder_ckpt_files, unet_ckpt_files = get_monai_training_ckpt_files(output_dir, training_name)\n",
    "    # loop over ckpts\n",
    "    for autoenc_ckpt, unet_ckpt in zip(autencoder_ckpt_files, unet_ckpt_files):\n",
    "        epoch_num = strip_epoch_num_from_ckpt(autoenc_ckpt, framework_type)\n",
    "        # load model\n",
    "        model_dict = get_monai_model_dict(BUNDLE, training_args, autoenc_ckpt, unet_ckpt)\n",
    "        # instantiate ldm classifier\n",
    "        ldm_clf = MonaiLdmClassifier(**model_dict)\n",
    "        # run classification\n",
    "        l2_labels_pred, l1_labels_pred, true_labels = ldm_clf.classify_dataset(dataset=ds,\n",
    "                                                                               batch_size=1,\n",
    "                                                                               n_trials=n_trials,\n",
    "                                                                               t_sampling_stride=t_sampling_stride)\n",
    "        # save results\n",
    "        clf_res_per_epoch[epoch_num] = {\n",
    "          'true_labels': true_labels,\n",
    "          'l1_pred_labels': l1_labels_pred,\n",
    "          'l2_pred_labels': l2_labels_pred,\n",
    "        }\n",
    "        with open(os.path.join(clf_dir, f'predictions_{n_pred_files}'), 'wb') as f:\n",
    "            pickle.dump(clf_res_per_epoch, f)\n",
    "        \n",
    "        # delete model\n",
    "        del model\n",
    "        del ldm_clf\n",
    "    \n",
    "    return clf_res_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a580e0d3-e221-4bf6-83db-11b7916d24bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# TODO - define the correct path to data\n",
    "sys.path.append('./brats-mri/brats_mri_class_cond/scripts')\n",
    "from ct_rsna import CTSubset\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cdbdcf-a8af-4971-85cd-6f950715e4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "train_dir = './data/ct-rsna/train'\n",
    "val_dir = './data/ct-rsna/validation'\n",
    "\n",
    "subset_len = 1\n",
    "ds = CTSubset(data_dir=val_dir, labels_file='validation_set_dropped_nans.csv', size=256, flip_prob=0., subset_len=subset_len)\n",
    "\n",
    "# LDM classifier params\n",
    "t_sampling_stride = 50\n",
    "n_trials = 1\n",
    "\n",
    "# training dir\n",
    "output_dir = './data/outputs'\n",
    "training_name = 'brats001'\n",
    "\n",
    "# evaluate\n",
    "clf_res_per_epoch = evaluate_accuracy_over_epochs(output_dir, \n",
    "                                                  training_name, \n",
    "                                                  ds, \n",
    "                                                  t_sampling_stride,\n",
    "                                                  n_trials)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
